{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitmod3nlppythonhqpzdnr6ab3f1781bf094d7f825e8de4eadf86c2",
   "display_name": "Python 3.8.5 64-bit ('mod3_nlp_python-Hqpzdnr6')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Uso da biblioteca SpaCy\n",
    "### https://spacy.io/\n",
    "### pip install -U spacy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "## 1. Importando dados da preparação"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_MPO_PREPARADOS = '../../Data/Processed/mpo_preparados.parquet'\n",
    "\n",
    "df_mpo = pd.read_parquet(PARQUET_MPO_PREPARADOS)"
   ]
  },
  {
   "source": [
    "## Iniciando: Tokenização, índices e atributos léxicos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Olá meu nome é Marcelo e tenho 46 anos.\nid: 0\t token: Olá\t pos_i: 0\t String? True\t Número? False\t Pontuação? False\nid: 1\t token: meu\t pos_i: 4\t String? True\t Número? False\t Pontuação? False\nid: 2\t token: nome\t pos_i: 8\t String? True\t Número? False\t Pontuação? False\nid: 3\t token: é\t pos_i: 13\t String? True\t Número? False\t Pontuação? False\nid: 4\t token: Marcelo\t pos_i: 15\t String? True\t Número? False\t Pontuação? False\nid: 5\t token: e\t pos_i: 23\t String? True\t Número? False\t Pontuação? False\nid: 6\t token: tenho\t pos_i: 25\t String? True\t Número? False\t Pontuação? False\nid: 7\t token: 46\t pos_i: 31\t String? False\t Número? True\t Pontuação? False\nid: 8\t token: anos\t pos_i: 34\t String? True\t Número? False\t Pontuação? False\nid: 9\t token: .\t pos_i: 38\t String? False\t Número? False\t Pontuação? True\n"
     ]
    }
   ],
   "source": [
    "# Importe a classe do idioma portugues\n",
    "from spacy.lang.pt import Portuguese\n",
    "\n",
    "# Crie um objeto nlp\n",
    "nlp = Portuguese()\n",
    "\n",
    "# Processe o texto\n",
    "doc = nlp(\"Olá meu nome é Marcelo e tenho 46 anos.\")\n",
    "\n",
    "# Imprima o texto do documento\n",
    "print(doc.text)\n",
    "\n",
    "# Imprima alguns atributos léxicos\n",
    "for token in doc:\n",
    "    print(f\"id: {token.i}\\t\", f\"token: {doc[token.i]}\\t\", f\"pos_i: {token.idx}\\t\", f\"String? {token.is_alpha}\\t\", f\"Número? {token.is_digit}\\t\", f\"Pontuação? {token.is_punct}\")"
   ]
  },
  {
   "source": [
    "## Importando pequeno modelo treinado em pt\n",
    "## python -m spacy download pt_core_news_sm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pt_core_news_sm\n",
    "\n",
    "nlp = pt_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Olá meu nome é Marcelo e tenho 46 anos.\n"
     ]
    }
   ],
   "source": [
    "# Processe o texto\n",
    "doc = nlp(\"Olá meu nome é Marcelo e tenho 46 anos.\")\n",
    "\n",
    "# Imprima o texto do documento\n",
    "print(doc.text)"
   ]
  },
  {
   "source": [
    "## Observando previsão de classe gramatical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Olá VERB nsubj Marcelo\nmeu DET det nome\nnome NOUN obj Olá\né AUX cop Marcelo\nMarcelo PROPN ROOT Marcelo\ne CCONJ cc tenho\ntenho VERB conj Marcelo\n46 NUM nummod anos\nanos NOUN obj tenho\n. PUNCT punct Marcelo\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    # Imprimir o texto e a classe gramatical prevista (pos_), marcador de dependência (dep_), índice da palavra principal (head) \n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'determiner'"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.explain(\"DET\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'coordinating conjunction'"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "spacy.explain(\"CCONJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'numeric modifier'"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "spacy.explain(\"nummod\")"
   ]
  },
  {
   "source": [
    "## Observando as entidades nomeadas identificadas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Olá MISC\nMarcelo MISC\n"
     ]
    }
   ],
   "source": [
    "# Iterar nas entidades previstas\n",
    "for ent in doc.ents:\n",
    "    # Imprimir o texto da entidade e seu marcador\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Miscellaneous entities, e.g. events, nationalities, products or works of art'"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "spacy.explain(\"MISC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Olá meu nome é Marcelo, moro no Rio de Janeiro e trabalho na Microsoft.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Olá MISC\nMarcelo MISC\nRio de Janeiro LOC\nMicrosoft ORG\n"
     ]
    }
   ],
   "source": [
    "# Iterar nas entidades previstas\n",
    "for ent in doc.ents:\n",
    "    # Imprimir o texto da entidade e seu marcador\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Non-GPE locations, mountain ranges, bodies of water'"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "spacy.explain(\"LOC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "source": [
    "## Usando comparadores. Além de textos podem comparar atributos léxicos, lematização e outros"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Olá meu nome é Marcelo, moro no Rio de Janeiro e trabalho na Apple com iPhone X. Já trabalhei com iPhone 6 e nunca irei trabalhar com o iPhone 13.\n"
     ]
    }
   ],
   "source": [
    "# Processe o texto\n",
    "doc = nlp(\"Olá meu nome é Marcelo, moro no Rio de Janeiro e trabalho na Apple com iPhone X. Já trabalhei com iPhone 6 e nunca irei trabalhar com o iPhone 13.\")\n",
    "\n",
    "# Imprima o texto do documento\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Olá MISC\nMarcelo MISC\nRio de Janeiro LOC\nApple ORG\n"
     ]
    }
   ],
   "source": [
    "# Iterar nas entidades previstas\n",
    "for ent in doc.ents:\n",
    "    # Imprimir o texto da entidade e seu marcador\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trabalho\niPhone X.\ntrabalhei\niPhone 6\ntrabalhar\niPhone 13\n"
     ]
    }
   ],
   "source": [
    "# Importar o Comparador (Matcher)\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Inicializar o comparador com o vocabulário. Obrigatório\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Adicionar a expressão ao comparador\n",
    "pattern = [[{\"TEXT\": \"iPhone\"},{\"IS_DIGIT\":True}]\n",
    "          ,[{\"LOWER\": \"iphone\"},{\"LOWER\":\"x.\"}]\n",
    "          ,[{\"LEMMA\": \"trabalhar\"}]]\n",
    "\n",
    "\n",
    "matcher.add(\"IPHONE_PATTERN\", pattern)\n",
    "\n",
    "# Chamar o matcher no doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Iterar nas correspondências\n",
    "for match_id, start, end in matches:\n",
    "    # Selecionar a partição que houve correspondência\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}